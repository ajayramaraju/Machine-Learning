{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVH8gB0q84uPzc/89oBoei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajayramaraju/Machine-Learning/blob/main/Conditional_GAN_using_Numbers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WElUGSmB9RtN"
      },
      "outputs": [],
      "source": [
        "# supress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUGqctLnbkSv",
        "outputId": "9f98c342-39a4-45e5-f335-184d6447e6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dataset\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NRZnw1Hblv-",
        "outputId": "6f06d52b-f92c-40f7-fef5-56d1e6c3bedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height =28,28\n",
        "img_channel = 1\n",
        "img_shape = (img_width, img_height, img_channel)\n",
        "num_classes = 10\n",
        "z_dim = 100"
      ],
      "metadata": {
        "id": "sRcgDt3fbsuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import UpSampling2D, Reshape, Activation, Conv2D, BatchNormalization, LeakyReLU, Input, Flatten, multiply\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.models import Sequential, Model\n",
        "\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128*7*7, activation = 'relu', input_shape = (z_dim, )))\n",
        "    model.add(Reshape((7,7,128)))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(64, kernel_size = 3, strides = 1, padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(1, kernel_size = 3 , strides = 1, padding='same'))\n",
        "    model.add(Activation('tanh'))\n",
        "\n",
        "    z = Input(shape= (z_dim,))\n",
        "    label = Input(shape=(1,), dtype = 'int32')\n",
        "\n",
        "    label_embedding = Embedding(num_classes, z_dim, input_length = 1)(label)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    joined = multiply([z, label_embedding])\n",
        "\n",
        "    img = model(joined)\n",
        "    return Model([z, label], img)\n",
        "\n",
        "generator = build_generator()\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja68gpc3bwfK",
        "outputId": "e3303eff-32f1-46da-9a37-2024412074ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 1, 100)               1000      ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)        [(None, 100)]                0         []                            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 100)                  0         ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " multiply (Multiply)         (None, 100)                  0         ['input_1[0][0]',             \n",
            "                                                                     'flatten[0][0]']             \n",
            "                                                                                                  \n",
            " sequential (Sequential)     (None, 28, 28, 1)            856193    ['multiply[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 857193 (3.27 MB)\n",
            "Trainable params: 856809 (3.27 MB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dropout, Concatenate\n",
        "import numpy as np\n",
        "\n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size = 3, strides = 2, input_shape = (28,28,2), padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(Conv2D(64, kernel_size = 3, strides = 2, padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(Conv2D(128, kernel_size = 3, strides = 2, padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha = 0.02))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    img = Input(shape= (img_shape))\n",
        "    label = Input(shape= (1,), dtype = 'int32')\n",
        "\n",
        "    label_embedding = Embedding(input_dim = num_classes, output_dim = np.prod(img_shape), input_length = 1)(label)\n",
        "    label_embedding = Flatten()(label_embedding)\n",
        "    label_embedding = Reshape(img_shape)(label_embedding)\n",
        "\n",
        "    concat = Concatenate(axis = -1)([img, label_embedding])\n",
        "    prediction = model(concat)\n",
        "    return Model([img, label], prediction)\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKZVJQIrbyYz",
        "outputId": "783f9b0e-c31d-434a-eec5-6efe9a230e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 1, 784)               7840      ['input_4[0][0]']             \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 784)                  0         ['embedding_1[0][0]']         \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)         (None, 28, 28, 1)            0         ['flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 28, 28, 2)            0         ['input_3[0][0]',             \n",
            "                                                                     'reshape_1[0][0]']           \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)   (None, 1)                    95905     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 103745 (405.25 KB)\n",
            "Trainable params: 103297 (403.50 KB)\n",
            "Non-trainable params: 448 (1.75 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "discriminator.compile(loss = 'binary_crossentropy', optimizer = Adam(0.0002, 0.5), metrics = ['accuracy'])\n",
        "\n",
        "z = Input(shape=(z_dim,))\n",
        "label = Input(shape= (1,))\n",
        "img = generator([z,label])\n",
        "\n",
        "discriminator.trainable = False\n",
        "prediction = discriminator([img, label])\n",
        "\n",
        "cgan = Model([z, label], prediction)\n",
        "cgan.compile(loss= 'binary_crossentropy', optimizer = Adam(0.0002, 0.5))"
      ],
      "metadata": {
        "id": "byewgXSAb0pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epochs, batch_size, save_interval):\n",
        "    (X_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "    X_train = (X_train - 127.5) / 127.5\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "    real = np.ones(shape=(batch_size, 1))\n",
        "    fake = np.zeros(shape=(batch_size, 1))\n",
        "\n",
        "    for iteration in range(epochs):\n",
        "\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        imgs, labels = X_train[idx], y_train[idx]\n",
        "\n",
        "        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "        gen_imgs = generator.predict([z, labels])\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch([imgs, labels], real)\n",
        "        d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        z = np.random.normal(0, 1, size=(batch_size, z_dim))\n",
        "        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
        "\n",
        "        g_loss = cgan.train_on_batch([z, labels], real)\n",
        "\n",
        "        if iteration % save_interval == 0:\n",
        "            print('{} [D loss: {}, accuracy: {:.2f}] [G loss: {}]'.format(iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "            save_image(iteration)"
      ],
      "metadata": {
        "id": "bxt_liJwb5Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('images'):\n",
        "    os.mkdir('images')"
      ],
      "metadata": {
        "id": "bA0FJE1ofMQE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def save_image(epoch):\n",
        "    r, c = 2,5\n",
        "    z = np.random.normal(0,1,(r*c, z_dim))\n",
        "    labels = np.arange(0,10).reshape(-1,1)\n",
        "    gen_image = generator.predict([z,labels])\n",
        "    gen_image = 0.5 * gen_image + 0.5\n",
        "\n",
        "    fig, axes = plt.subplots(r,c, figsize = (10,10))\n",
        "    count = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axes[i,j].imshow(gen_image[count,:,:,0],cmap = 'gray')\n",
        "            axes[i,j].axis('off')\n",
        "            axes[i,j].set_title(\"Digit: %d\" % labels[count])\n",
        "            count+=1\n",
        "    plt.savefig('images/cgan_%d.jpg' % epoch)\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "WY09hNaSb7S9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train network\n",
        "train(50000, 128, 1000)"
      ],
      "metadata": {
        "id": "e1SlxOWqb9Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yxws5pJrb_kF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}