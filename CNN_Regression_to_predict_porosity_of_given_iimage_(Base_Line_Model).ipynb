{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ygWXJWmTyD8Ulpo7bxubgXl6HCBkLoUa",
      "authorship_tag": "ABX9TyO/89E9vf6jQzNhVOtY0nar",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajayramaraju/Machine-Learning/blob/main/CNN_Regression_to_predict_porosity_of_given_iimage_(Base_Line_Model).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j-avuN9lBaE"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "JPL0PYVBlYFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/microstructure_dataset'\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,  # Randomly rotate images by up to 20 degrees\n",
        "    #width_shift_range=0.2,\n",
        "    shear_range=0.2,  # Shear transformations\n",
        "    zoom_range=0.2,  # Randomly zoom in/out by up to 20%\n",
        "    horizontal_flip=True,  # Randomly flip horizontally\n",
        "    #fill_mode='constant'  # Fill mode for empty pixels\n",
        ")\n",
        "\n",
        "# Loop through our porosity directories and apply data augmentation\n",
        "for porosity_dir in os.listdir(data_dir):\n",
        "    if os.path.isdir(os.path.join(data_dir, porosity_dir)):\n",
        "        print(f\"Augmenting images in {porosity_dir}...\")\n",
        "        porosity_path = os.path.join(data_dir, porosity_dir)\n",
        "        images = os.listdir(porosity_path)\n",
        "        for image in images:\n",
        "            img = keras.preprocessing.image.load_img(os.path.join(porosity_path, image))\n",
        "            img = keras.preprocessing.image.img_to_array(img)\n",
        "            img = img.reshape((1,) + img.shape)\n",
        "\n",
        "\n",
        "            i = 0\n",
        "            for batch in datagen.flow(img, save_to_dir=porosity_path, save_prefix='image', save_format='jpg'):\n",
        "                i += 1\n",
        "                if i == 4:\n",
        "                    break\n",
        "\n",
        "print(\"Data augmentation complete.\")"
      ],
      "metadata": {
        "id": "W435i2V1ldzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the paths\n",
        "data_dir = '/content/drive/MyDrive/microstructure_dataset'\n",
        "output_dir = '/content/drive/MyDrive/project_directory'\n",
        "\n",
        "# Define the split ratios (e.g., 80-10-10)\n",
        "train_ratio = 0.80\n",
        "validation_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "# Create directories for the three sets\n",
        "os.makedirs(os.path.join(output_dir, 'training'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'validation'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'testing'), exist_ok=True)\n",
        "\n",
        "# Loop through the porosity directories and split the data\n",
        "for porosity_dir in os.listdir(data_dir):\n",
        "    if os.path.isdir(os.path.join(data_dir, porosity_dir)):\n",
        "        images = os.listdir(os.path.join(data_dir, porosity_dir))\n",
        "        random.shuffle(images)\n",
        "\n",
        "        # Shuffleing to randomize the order\n",
        "        train_images, validation_images = train_test_split(images, test_size=validation_ratio, random_state=42)\n",
        "        test_images = list(set(images) - set(train_images) - set(validation_images))\n",
        "\n",
        "        for image in train_images:\n",
        "            source = os.path.join(data_dir, porosity_dir, image)\n",
        "            destination = os.path.join(output_dir, 'training', porosity_dir, image)\n",
        "            os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
        "            shutil.copy(source, destination)\n",
        "\n",
        "        for image in validation_images:\n",
        "            source = os.path.join(data_dir, porosity_dir, image)\n",
        "            destination = os.path.join(output_dir, 'validation', porosity_dir, image)\n",
        "            os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
        "            shutil.copy(source, destination)\n",
        "\n",
        "        for image in test_images:\n",
        "            source = os.path.join(data_dir, porosity_dir, image)\n",
        "            destination = os.path.join(output_dir, 'testing', porosity_dir, image)\n",
        "            os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
        "            shutil.copy(source, destination)\n",
        "\n",
        "print(\"Data splitting complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2W3Z13Em8Gx",
        "outputId": "064f6531-b1b4-465a-df71-8c710d9bec91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data splitting complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pre Processing:"
      ],
      "metadata": {
        "id": "ooyPScTU455w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the paths to your data\n",
        "data_dir = '/content/drive/MyDrive/project_directory'\n",
        "output_dir = '/content/drive/MyDrive/preprocessed_data'\n",
        "\n",
        "# Create directories for preprocessed data\n",
        "os.makedirs(os.path.join(output_dir, 'training'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'validation'), exist_ok=True)\n",
        "os.makedirs(os.path.join(output_dir, 'testing'), exist_ok=True)\n",
        "\n",
        "# Function to preprocess and save images\n",
        "def preprocess_images(source_dir, destination_dir):\n",
        "    for porosity_dir in os.listdir(source_dir):\n",
        "        if os.path.isdir(os.path.join(source_dir, porosity_dir)):\n",
        "            for image in os.listdir(os.path.join(source_dir, porosity_dir)):\n",
        "                img_path = os.path.join(source_dir, porosity_dir, image)\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale\n",
        "                img = cv2.resize(img, (224, 224))  # Resize to a standard size (adjust as needed)\n",
        "                img = img / 255.0  # Normalize pixel values to [0, 1]\n",
        "\n",
        "                # Save the preprocessed image\n",
        "                destination_path = os.path.join(destination_dir, porosity_dir, image)\n",
        "                os.makedirs(os.path.dirname(destination_path), exist_ok=True)\n",
        "                cv2.imwrite(destination_path, (img * 175).astype(np.uint8))  # Convert back to 8-bit format\n",
        "\n",
        "# Preprocess the training set\n",
        "preprocess_images(os.path.join(data_dir, 'training'), os.path.join(output_dir, 'training'))\n",
        "\n",
        "# Preprocess the validation set\n",
        "preprocess_images(os.path.join(data_dir, 'validation'), os.path.join(output_dir, 'validation'))\n",
        "\n",
        "# Preprocess the testing set\n",
        "preprocess_images(os.path.join(data_dir, 'testing'), os.path.join(output_dir, 'testing'))\n",
        "\n",
        "print(\"Data preprocessing complete.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1AomnmW48kK",
        "outputId": "d93e9d89-e9ea-4273-bd66-0bcdb155a9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data preprocessing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model:"
      ],
      "metadata": {
        "id": "6jMMhI8tAO_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create a Sequential model\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1,))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
      ],
      "metadata": {
        "id": "bOVE1QM-AOAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training:"
      ],
      "metadata": {
        "id": "IN-e86p4BkCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "\n",
        "for porosity_dir in os.listdir('/content/drive/MyDrive/preprocessed_data/training'):\n",
        "    if os.path.isdir(os.path.join('/content/drive/MyDrive/preprocessed_data/training', porosity_dir)):\n",
        "        # Load images in this porosity category\n",
        "        image_paths = os.listdir(os.path.join('/content/drive/MyDrive/preprocessed_data/training', porosity_dir))\n",
        "        for image_path in image_paths:\n",
        "            # Load the image\n",
        "            img = cv2.imread(os.path.join('/content/drive/MyDrive/preprocessed_data/training', porosity_dir, image_path), cv2.IMREAD_GRAYSCALE)\n",
        "            # Append the image to X_train\n",
        "            X_train.append(img)\n",
        "            # Extract the porosity value from the directory name\n",
        "            label = int(porosity_dir.replace('porosity_', ''))\n",
        "            # Append the label to Y_train\n",
        "            Y_train.append(label)\n",
        "\n",
        "# Convert X_train and Y_train to NumPy arrays for compatibility with model.fit\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "# Verify shapes\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"Y_train shape:\", Y_train.shape)\n",
        "\n",
        "print(X_train)\n",
        "print(Y_train)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd1rGEX3Blo7",
        "outputId": "7ee55ba8-5d12-4126-fa73-3dd8a1057112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (194, 224, 224)\n",
            "Y_train shape: (194,)\n",
            "[[[175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  ...\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]]\n",
            "\n",
            " [[175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  ...\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]]\n",
            "\n",
            " [[175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  ...\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  ...\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]]\n",
            "\n",
            " [[175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  ...\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]]\n",
            "\n",
            " [[175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  ...\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]\n",
            "  [175 175 175 ... 175 175 175]]]\n",
            "[50 50 50 50 36 36 36 36 36 31 31 31 31 31 38 38 38 38 39 39 39 39 39 30\n",
            " 30 30 30 30 37 37 37 37 15 15 15 15 12 12 12 12 12 24 24 24 24 24 23 23\n",
            " 23 23 23 48 48 48 48 48 46 46 46 46 46 41 41 41 41 41 22 22 22 22 22 25\n",
            " 25 25 25 25 13 13 13 13 14 14 14 14 14 40 40 40 40 40 47 47 47 47 47 49\n",
            " 49 49 49 49 32 32 32 32 32 35 35 35 35 35 34 34 34 34 33 33 33 33 33 42\n",
            " 42 42 42 42 45 45 45 45 45 11 11 11 11 11 16 16 16 16 16 29 29 29 29 29\n",
            " 20 20 20 20 27 27 27 27 27 18 18 18 18 44 44 44 44 44 43 43 43 43 43 26\n",
            " 26 26 26 26 19 19 19 19 21 21 21 21 17 17 17 17 17 28 28 28 28 28 10 10\n",
            " 10 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training\n"
      ],
      "metadata": {
        "id": "T3tfZYxjvvHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjqxem7zG3bh",
        "outputId": "9c6a8b1f-bcbf-4ac7-d709-f917bd25aadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 21s 3s/step - loss: 773829.3125 - mae: 464.9102 - mse: 773829.3125 - val_loss: 227.2538 - val_mae: 13.8271 - val_mse: 227.2538\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 20s 3s/step - loss: 318.5288 - mae: 14.5270 - mse: 318.5288 - val_loss: 65.8403 - val_mae: 6.8465 - val_mse: 65.8403\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 18s 3s/step - loss: 123.3511 - mae: 9.4386 - mse: 123.3511 - val_loss: 121.9852 - val_mae: 9.7131 - val_mse: 121.9852\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 18s 3s/step - loss: 97.1469 - mae: 8.3420 - mse: 97.1469 - val_loss: 107.4259 - val_mae: 9.2096 - val_mse: 107.4259\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 18s 3s/step - loss: 85.7441 - mae: 7.7906 - mse: 85.7441 - val_loss: 34.8374 - val_mae: 4.9234 - val_mse: 34.8374\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 20s 3s/step - loss: 97.5715 - mae: 8.1286 - mse: 97.5715 - val_loss: 30.3188 - val_mae: 4.5574 - val_mse: 30.3188\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 18s 3s/step - loss: 60.1617 - mae: 6.3782 - mse: 60.1617 - val_loss: 33.2965 - val_mae: 4.7458 - val_mse: 33.2965\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 18s 3s/step - loss: 29.1772 - mae: 4.4461 - mse: 29.1772 - val_loss: 26.1414 - val_mae: 4.1234 - val_mse: 26.1414\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 18s 3s/step - loss: 23.7262 - mae: 3.9692 - mse: 23.7262 - val_loss: 34.1902 - val_mae: 4.9145 - val_mse: 34.1902\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 19s 3s/step - loss: 11.3871 - mae: 2.7777 - mse: 11.3871 - val_loss: 36.3758 - val_mae: 5.1178 - val_mse: 36.3758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sYJFmJHtvxcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "test_data_dir = '/content/drive/MyDrive/preprocessed_data/testing'\n",
        "\n",
        "# Check if the test data directory exists\n",
        "if not os.path.exists(test_data_dir):\n",
        "    print(f\"Test data directory not found: {test_data_dir}\")\n",
        "else:\n",
        "    # Create empty lists to store test data\n",
        "    X_test = []\n",
        "    Y_test = []\n",
        "\n",
        "    # Iterate through the test data directories\n",
        "    for porosity_dir in os.listdir(test_data_dir):\n",
        "        if os.path.isdir(os.path.join(test_data_dir, porosity_dir)):\n",
        "            # Load images in this porosity category\n",
        "            image_paths = os.listdir(os.path.join(test_data_dir, porosity_dir))\n",
        "            for image_path in image_paths:\n",
        "                # Load the test image\n",
        "                img = cv2.imread(os.path.join(test_data_dir, porosity_dir, image_path), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # Append the test image to X_test\n",
        "                X_test.append(img)\n",
        "\n",
        "                # Extract the true porosity value from the directory name\n",
        "                label = int(porosity_dir.replace('porosity_', ''))\n",
        "\n",
        "                # Append the true porosity value to Y_test\n",
        "                Y_test.append(label)\n",
        "\n",
        "    # Convert X_test and Y_test to NumPy arrays\n",
        "    X_test = np.array(X_test)\n",
        "    Y_test = np.array(Y_test)\n",
        "\n",
        "    # Verify shapes\n",
        "    print(\"X_test shape:\", X_test.shape)\n",
        "    print(\"Y_test shape:\", Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoFdwZL0IFng",
        "outputId": "97672d75-be9e-4538-bc32-8bb65d8cdb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (41, 224, 224)\n",
            "Y_test shape: (41,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae, mse = model.evaluate(X_test, Y_test)\n",
        "\n",
        "# Print the evaluation results\n",
        "print(\"Test Loss (MSE):\", loss)\n",
        "print(\"Test MAE:\", mae)\n",
        "print(\"Test MSE:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AENOUljlJg2F",
        "outputId": "6d2303f9-c92f-4533-f488-417eac1fe034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 306ms/step - loss: 17.1860 - mae: 3.2502 - mse: 17.1860\n",
            "Test Loss (MSE): 17.186031341552734\n",
            "Test MAE: 3.2501883506774902\n",
            "Test MSE: 17.186031341552734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "image_path = '/content/drive/MyDrive/preprocessed_data/testing/porosity_40/40 (3).jpg'  # Provide the path to your image\n",
        "input_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Preprocess the image\n",
        "input_image = cv2.resize(input_image, (224, 224))\n",
        "input_image = input_image / 255.0  # Normalize pixel values to [0, 1]\n",
        "input_image = input_image.reshape(1, 224, 224, 1)  # Reshape for model input\n",
        "# Use the model for prediction\n",
        "predicted_porosity = model.predict(input_image)\n",
        "\n",
        "# Print the predicted porosity\n",
        "print(\"Predicted Porosity:\", predicted_porosity[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ybqN-SJ_zW",
        "outputId": "9484072b-3937-455e-9d70-77cbaab7e69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n",
            "Predicted Porosity: 0.18628031\n"
          ]
        }
      ]
    }
  ]
}